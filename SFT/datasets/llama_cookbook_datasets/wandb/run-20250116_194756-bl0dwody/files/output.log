Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.63it/s]
--> Model genesis1SubHub/Llama3.3_Acronym_X_Text

--> genesis1SubHub/Llama3.3_Acronym_X_Text has 12763.343395 Million params

trainable params: 5,898,240 || all params: 12,769,241,635 || trainable%: 0.0462
bFloat16 enabled for mixed precision - using bfSixteen policy
--> applying fsdp activation checkpointing...
--> Training Set Length = 210
--> Validation Set Length = 90
length of dataset_train 210
custom_data_collator is used
--> Num of Training Set Batches loaded = 26
--> Num of Validation Set Batches loaded = 11
--> Num of Validation Set Batches loaded = 11
model_name : genesis1SubHub/Llama3.3_Acronym_X_Text
tokenizer_name : meta-llama/Llama-3.2-11B-Vision-Instruct
enable_fsdp : True
low_cpu_fsdp : False
run_validation : True
batch_size_training : 1
batching_strategy : padding
context_length : 4096
gradient_accumulation_steps : 1
gradient_clipping : False
gradient_clipping_threshold : 1.0
num_epochs : 3
max_train_step : 0
max_eval_step : 0
num_workers_dataloader : 1
lr : 1e-05
weight_decay : 0.0
gamma : 0.85
seed : 42
use_fp16 : False
mixed_precision : True
val_batch_size : 1
peft_method : lora
use_peft : True
from_peft_checkpoint :
output_dir : /home/ubuntu/save_model/PEFT
freeze_layers : False
num_freeze_layers : 1
freeze_LLM_only : False
quantization : None
one_gpu : False
save_model : True
dist_checkpoint_root_folder : /home/ubuntu/save_model/
dist_checkpoint_folder : checkpoints
save_optimizer : False
use_fast_kernels : True
use_wandb : True
save_metrics : True
flop_counter : False
flop_counter_start : 3
use_profiler : False
profiler_dir : PATH/to/save/profiler/results
dataset : custom_dataset


mixed_precision : True
use_fp16 : False
sharding_strategy : ShardingStrategy.FULL_SHARD
hsdp : False
sharding_group_size : 0
replica_group_size : 0
checkpoint_type : StateDictType.SHARDED_STATE_DICT
fsdp_activation_checkpointing : True
fsdp_cpu_offload : False
pure_bf16 : False
optimizer : AdamW


task_type : CAUSAL_LM
peft_type : LORA
auto_mapping : None
base_model_name_or_path : genesis1SubHub/Llama3.3_Acronym_X_Text
revision : None
inference_mode : False
r : 8
target_modules : {'v_proj', 'q_proj'}
exclude_modules : None
lora_alpha : 32
lora_dropout : 0.05
fan_in_fan_out : False
bias : none
use_rslora : False
modules_to_save : None
init_lora_weights : True
layers_to_transform : None
layers_pattern : None
rank_pattern : {}
alpha_pattern : {}
megatron_config : None
megatron_core : megatron.core
loftq_config : {}
eva_config : None
use_dora : False
layer_replication : None
runtime_config : LoraRuntimeConfig(ephemeral_gpu_offload=False)
lora_bias : False
_custom_modules : None
dataset : custom_dataset
file : /home/ubuntu/llama-cookbook-main_20250116/getting-started/finetuning/datasets/pg16_WPAFB_dataset.py
train_split : train
test_split : test
data_path :
Starting epoch 0/3
train_config.max_train_step: 0
/usr/lib/python3/dist-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                                [0m| 0/26 [00:00<?, ?it/s][0mTraceback (most recent call last):
Pixels Values after reshape torch.Size([4, 3, 560, 560])
Aspect Ratio Ids after reshape torch.Size([1, 1])
  File "/home/ubuntu/llama-cookbook-main_20250116/src/execute.py", line 45, in <module>
    main(**kwargs)
  File "/home/ubuntu/llama-cookbook-main_20250116/src/llama_recipes/finetuning.py", line 433, in main
    results = train(
  File "/home/ubuntu/llama-cookbook-main_20250116/src/llama_recipes/utils/train_utils.py", line 153, in train
    loss = model(**batch).loss
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 864, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/peft/peft_model.py", line 1719, in forward
    return self.base_model(
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/ubuntu/SubHub-South-TX/backend/modeling_mllama_vision.py", line 1339, in forward
    vision_outputs = self.vision_model(
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ubuntu/SubHub-South-TX/backend/modeling_mllama_vision.py", line 1049, in forward
    patch_embeds = self.patch_embedding(pixel_values.to(self.dtype).to(self.device))
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/usr/lib/python3/dist-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (CUDABFloat16Type) should be the same
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/ubuntu/llama-cookbook-main_20250116/src/execute.py", line 45, in <module>
[rank0]:     main(**kwargs)
[rank0]:   File "/home/ubuntu/llama-cookbook-main_20250116/src/llama_recipes/finetuning.py", line 433, in main
[rank0]:     results = train(
[rank0]:   File "/home/ubuntu/llama-cookbook-main_20250116/src/llama_recipes/utils/train_utils.py", line 153, in train
[rank0]:     loss = model(**batch).loss
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 864, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/ubuntu/.local/lib/python3.10/site-packages/peft/peft_model.py", line 1719, in forward
[rank0]:     return self.base_model(
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/ubuntu/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
[rank0]:     return self.model.forward(*args, **kwargs)
[rank0]:   File "/home/ubuntu/SubHub-South-TX/backend/modeling_mllama_vision.py", line 1339, in forward
[rank0]:     vision_outputs = self.vision_model(
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/ubuntu/SubHub-South-TX/backend/modeling_mllama_vision.py", line 1049, in forward
[rank0]:     patch_embeds = self.patch_embedding(pixel_values.to(self.dtype).to(self.device))
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/conv.py", line 554, in forward
[rank0]:     return self._conv_forward(input, self.weight, self.bias)
[rank0]:   File "/usr/lib/python3/dist-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
[rank0]:     return F.conv2d(
[rank0]: RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (CUDABFloat16Type) should be the same
