{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8f9195-a294-46ed-a520-5e99380bd1f6",
   "metadata": {},
   "source": [
    "## Preparing Inputs for Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d086212-f08e-4430-bfa5-331bc994f8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from transformers import AutoProcessor \n",
    "\n",
    "civil_plans_dict=load_dataset(\"genesis1SubHub/NHA-Civil-set\")\n",
    "civil_plans=civil_plans_dict[\"train\"]\n",
    "\n",
    "model_id=\"Qwen/Qwen2.5-VL-72B-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    max_pixels=12_845_056,\n",
    "    use_fast=True, # default for qwen2.5 processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d4cb83-174b-4390-b3c7-df9c80cfe127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples generated: 27\n",
      "  sample_structure\n",
      "    input_ids : torch.Size([1, 11040])\n",
      "    attention_mask : torch.Size([1, 11040])\n",
      "    pixel_values : torch.Size([43520, 1176])\n",
      "    image_grid_thw : torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "from src.eval_utils import create_samples\n",
    "from src.qwen_2_5_utils import generate_inputs_qwen2_5\n",
    "\n",
    "system_prompt = '''\n",
    "    You're a helpful assistant project manager in the construction industry.\n",
    "    Here's some example scopes of work:\n",
    "        1. \"Remove existing interior walls as specified.\"\n",
    "        2. \"Provide and install 7 roooftop mechanical units.\" \n",
    "        3. \"Design wood frame roof truss system\"\n",
    "    Place all scope items into a list, here's an example response with the example scopes above:\n",
    "        \"[\n",
    "            \"Remove existing interior walls as specified.\",\n",
    "            \"Provide and install 7 roooftop mechanical units.\",\n",
    "            \"Design wood frame roof truss system.\",\n",
    "        ]\"\n",
    "'''\n",
    "prompt=\"Using the given image, identify all scopes of work on the page. Some pages may have no scopes.\"\n",
    "input_lists=create_samples(\n",
    "    plans=civil_plans,\n",
    "    image_header=\"image\",\n",
    "    prompt=prompt,\n",
    "    input_generator=generate_inputs_qwen2_5,\n",
    "    system_prompt=system_prompt,\n",
    "    processor=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0e5bd-71eb-43d8-9110-05d149ae6b54",
   "metadata": {},
   "source": [
    "## Model Setup and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2014ef8-24ab-41b4-b583-83ec55d8e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 38/38 [00:28<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.qwen_2_5_utils import setup_model\n",
    "\n",
    "model=setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff4c9bd-ec33-46e9-846d-ecee60745968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation time elapsed: 65.0239 | New tokens generated: 242\n",
      "Generation time elapsed: 43.0581 | New tokens generated: 174\n",
      "Generation time elapsed: 66.7896 | New tokens generated: 294\n",
      "Generation time elapsed: 44.3964 | New tokens generated: 177\n",
      "Generation time elapsed: 105.9330 | New tokens generated: 500\n",
      "Generation time elapsed: 58.9016 | New tokens generated: 254\n",
      "Generation time elapsed: 58.2615 | New tokens generated: 256\n",
      "Generation time elapsed: 61.3150 | New tokens generated: 266\n",
      "Generation time elapsed: 106.4629 | New tokens generated: 500\n",
      "Generation time elapsed: 52.2392 | New tokens generated: 218\n",
      "Generation time elapsed: 106.5281 | New tokens generated: 500\n",
      "Generation time elapsed: 78.3927 | New tokens generated: 355\n",
      "Generation time elapsed: 64.0789 | New tokens generated: 284\n",
      "Generation time elapsed: 67.0620 | New tokens generated: 299\n",
      "Generation time elapsed: 51.2636 | New tokens generated: 211\n",
      "Generation time elapsed: 85.4708 | New tokens generated: 395\n",
      "Generation time elapsed: 75.4664 | New tokens generated: 341\n",
      "Generation time elapsed: 69.2538 | New tokens generated: 309\n",
      "Generation time elapsed: 58.8492 | New tokens generated: 259\n",
      "Generation time elapsed: 67.0488 | New tokens generated: 299\n",
      "Generation time elapsed: 28.3651 | New tokens generated: 97\n",
      "Generation time elapsed: 52.1790 | New tokens generated: 219\n",
      "Generation time elapsed: 71.4825 | New tokens generated: 319\n",
      "Generation time elapsed: 58.1137 | New tokens generated: 249\n",
      "Generation time elapsed: 76.1213 | New tokens generated: 345\n",
      "Generation time elapsed: 41.5347 | New tokens generated: 162\n",
      "Generation time elapsed: 96.7310 | New tokens generated: 450\n",
      "Total generation time elasped: 1972.5497\n"
     ]
    }
   ],
   "source": [
    "from src.eval_utils import generate\n",
    "\n",
    "trimmed_generated_ids=generate(\n",
    "    model=model,\n",
    "    samples=input_lists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611d9e1e-8352-464d-b2be-9d417dd5f34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def decode_outputs(\n",
    "    processor,\n",
    "    output_ids:list[list[torch.tensor]],\n",
    "    feature_extraction:bool=False\n",
    ")->list[str]:\n",
    "    '''\n",
    "    Args:\n",
    "        feature_extraction: If set to 'True', each token is a seperate element in the output list. Used to match tokens corresponding to a scope, for heatmap visualization.  \n",
    "    '''\n",
    "    text_outputs=[]\n",
    "    for output in output_ids:\n",
    "        decomposed_output_text=processor.batch_decode(\n",
    "            output if not feature_extraction else output[0], \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        text_outputs.extend(decomposed_output_text)\n",
    "    return text_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "894142d9-d07b-4fb9-9772-8210e1e49699",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_outputs=decode_outputs(processor=processor,output_ids=trimmed_generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce0cb7-143c-4378-94e9-a21a93489dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import json \n",
    "import types\n",
    "\n",
    "def extract_resp(raw_input):\n",
    "    json_str = re.search(\n",
    "        r\"\\[.*\\]\", raw_input, re.DOTALL\n",
    "    )\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3437d5-c378-47a8-add2-68bee2c9ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_outputs=[extract_resp(text_output) for text_output in text_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e789db-eb91-4975-b3f1-9f7014a4f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df=pd.DataFrame(\n",
    "    {\n",
    "        \"Civil outputs\":text_outputs,\n",
    "        \"page_id\": civil_plans[\"page_id\"],\n",
    "    }\n",
    ")\n",
    "df.to_csv(\"NHA_civil_model_outputs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f4667-ae6d-4425-a0ad-233d89efee2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
